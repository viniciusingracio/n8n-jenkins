---

# The following attributes should be set somewhere:
#
# bigbluebutton_backup_aws_key
# bigbluebutton_backup_aws_secret
# bigbluebutton_backup_aws_region
# bigbluebutton_backup_aws_endpoint
# bigbluebutton_backup_aws_bucket

- hosts:
  - mconf-live220
  vars:
    backup_date: '{{ ansible_date_time.date }}'
  tasks:
    - name: Determine paths to archive
      set_fact:
        to_copy:
          - { archive: "/metadata.tar.gz", path: [ "/var/bigbluebutton/published", "/var/bigbluebutton/unpublished", "/var/bigbluebutton/deleted" ] }
          - { archive: "/events.tar.gz", path: [ "/var/bigbluebutton/events" ] }
          - { archive: "/logs.tar.gz", path: [ "/var/log/bigbluebutton", "/var/log/nginx", "/var/log/bbb-apps-akka" ] }

    - name: Figure out failed recordings during process or publish
      shell: find /var/bigbluebutton/recording/status/processed /var/bigbluebutton/recording/status/published -name "*.fail" -exec basename {} \; | cut -d"-" -f1-2 | sort -u
      register: reg_failed_ids

    - name: Figure out failed recordings during sanity
      shell: find /var/bigbluebutton/recording/status/sanity -name "*.done" -exec basename {} \; | cut -d"." -f1 | sort -u
      register: reg_sanity_ids

    - name: Figure out raw path for failed recordings
      stat:
        path: '/var/bigbluebutton/recording/raw/{{ item }}'
      with_items: '{{ ( reg_failed_ids.stdout_lines + reg_sanity_ids.stdout_lines ) | unique }}'
      register: reg_raw_paths

    - name: Check if raw path exists
      set_fact:
        raw_path: '{{ raw_path | default([]) + [ item.stat.path ] }}'
      with_items: '{{ reg_raw_paths.results }}'
      when: item.stat.isdir is defined and item.stat.isdir

    - name: Add raw path to backup list
      set_fact:
        to_copy: '{{ to_copy + [ { "archive": "/raw.tar.gz", "path": raw_path } ]}}'
      when: raw_path is defined and raw_path | length > 0

    - name: Make sure the archive file doesn't exist yet
      file:
        path: '{{ item.archive }}'
        state: absent
      with_items: '{{ to_copy }}'
      become: yes

    - name: Archive backup
      archive:
        path: '{{ item.path }}'
        dest: '{{ item.archive }}'
      with_items: '{{ to_copy }}'
      become: yes
      async: 3600
      poll: 15

    - name: Upload backup to the cloud
      shell: docker run --rm -v /:/host:ro -v /var/log:/var/log -e AWS_ACCESS_KEY_ID={{ bigbluebutton_backup_aws_key }} -e AWS_SECRET_ACCESS_KEY={{ bigbluebutton_backup_aws_secret }} -e AWS_DEFAULT_REGION={{ bigbluebutton_backup_aws_region }} amazon/aws-cli --endpoint={{ bigbluebutton_backup_aws_endpoint }} s3 cp /host{{ item.archive }} s3://{{ bigbluebutton_backup_aws_bucket }}/{{ backup_date }}/{{ inventory_hostname }}{{ item.archive }} | tee -a /var/log/bigbluebutton-backup.log && sleep 30
      with_items: '{{ to_copy }}'
      register: result
      until: result is succeeded
      retries: 120
      delay: 30

    - name: Remove backup file after copy is finished
      file:
        path: '{{ item.archive }}'
        state: absent
      with_items: '{{ to_copy }}'
      become: yes

    - name: Cleanup
      shell: |
        rm -rf /var/bigbluebutton/published/ /var/bigbluebutton/unpublished/ /var/bigbluebutton/deleted/ /var/bigbluebutton/events/
        mkdir -p /var/bigbluebutton/published/presentation/ /var/bigbluebutton/published/presentation_video/ /var/bigbluebutton/unpublished/presentation/ /var/bigbluebutton/unpublished/presentation_video/ /var/bigbluebutton/deleted/presentation/ /var/bigbluebutton/deleted/presentation_video/ /var/bigbluebutton/events/
        chown -R bigbluebutton:bigbluebutton /var/bigbluebutton/published/ /var/bigbluebutton/unpublished/ /var/bigbluebutton/deleted/ /var/bigbluebutton/events/
      become: yes
      when: bigbluebutton_backup_cleanup is defined
      tags:
        - cleanup
